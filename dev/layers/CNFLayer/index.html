<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Continuous Normalizing Flows Layer · DiffEqFlux.jl</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-3"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-90474609-3', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://diffeqflux.sciml.ai/stable/layers/CNFLayer/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="DiffEqFlux.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DiffEqFlux.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">DiffEqFlux.jl: Generalized Physics-Informed and Scientific Machine Learning (SciML)</a></li><li><span class="tocitem">Ordinary Differential Equation (ODE) Tutorials</span><ul><li><a class="tocitem" href="../../examples/optimization_ode/">Optimization of Ordinary Differential Equations</a></li><li><a class="tocitem" href="../../examples/stiff_ode_fit/">Parameter Estimation on Highly Stiff Systems</a></li><li><a class="tocitem" href="../../examples/neural_ode_sciml/">Neural Ordinary Differential Equations with sciml_train</a></li><li><a class="tocitem" href="../../examples/mnist_neural_ode/">GPU-based MNIST Neural ODE Classifier</a></li><li><a class="tocitem" href="../../examples/mnist_conv_neural_ode/">Convolutional Neural ODE MNIST Classifier on GPU</a></li><li><a class="tocitem" href="../../examples/augmented_neural_ode/">Augmented Neural Ordinary Differential Equations</a></li><li><a class="tocitem" href="../../examples/collocation/">Smoothed Collocation for Fast Two-Stage Training</a></li><li><a class="tocitem" href="../../examples/neural_gde/">Neural Graph Differential Equations</a></li><li><a class="tocitem" href="../../examples/exogenous_input/">Handling Exogenous Input Signals</a></li><li><a class="tocitem" href="../../examples/normalizing_flows/">Continuous Normalizing Flows with GalacticOptim.jl</a></li></ul></li><li><span class="tocitem">Direct Usage with Optimizer Backends</span><ul><li><a class="tocitem" href="../../examples/neural_ode_galacticoptim/">Neural Ordinary Differential Equations with GalacticOptim.jl</a></li><li><a class="tocitem" href="../../examples/neural_ode_flux/">Neural Ordinary Differential Equations with Flux.train!</a></li></ul></li><li><span class="tocitem">Training Techniques</span><ul><li><a class="tocitem" href="../../examples/multiple_shooting/">Multiple Shooting</a></li><li><a class="tocitem" href="../../examples/local_minima/">Strategies to Avoid Local Minima</a></li><li><a class="tocitem" href="../../examples/prediction_error_method/">Prediction error method (PEM)</a></li><li><a class="tocitem" href="../../examples/divergence/">Handling Divergent and Unstable Trajectories</a></li><li><a class="tocitem" href="../../examples/multiple_nn/">Simultaneous Fitting of Multiple Neural Networks</a></li><li><a class="tocitem" href="../../examples/data_parallel/">Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching</a></li><li><a class="tocitem" href="../../examples/second_order_neural/">Neural Second Order Ordinary Differential Equation</a></li><li><a class="tocitem" href="../../examples/second_order_adjoints/">Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis</a></li><li><a class="tocitem" href="../../examples/minibatch/">Training a Neural Ordinary Differential Equation with Mini-Batching</a></li></ul></li><li><span class="tocitem">Stochastic Differential Equation (SDE) Tutorials</span><ul><li><a class="tocitem" href="../../examples/optimization_sde/">Optimization of Stochastic Differential Equations</a></li><li><a class="tocitem" href="../../examples/neural_sde/">Neural Stochastic Differential Equations</a></li></ul></li><li><span class="tocitem">Delay Differential Equation (DDE) Tutorials</span><ul><li><a class="tocitem" href="../../examples/delay_diffeq/">Delay Differential Equations</a></li></ul></li><li><span class="tocitem">Differential-Algebraic Equation (DAE) Tutorials</span><ul><li><a class="tocitem" href="../../examples/physical_constraints/">Enforcing Physical Constraints via Universal Differential-Algebraic Equations</a></li></ul></li><li><span class="tocitem">Partial Differential Equation (PDE) Tutorials</span><ul><li><a class="tocitem" href="../../examples/pde_constrained/">Partial Differential Equation (PDE) Constrained Optimization</a></li></ul></li><li><span class="tocitem">Hybrid and Jump Equation Tutorials</span><ul><li><a class="tocitem" href="../../examples/hybrid_diffeq/">Training Neural Networks in Hybrid Differential Equations</a></li><li><a class="tocitem" href="../../examples/bouncing_ball/">Bouncing Ball Hybrid ODE Optimization</a></li><li><a class="tocitem" href="../../examples/jump/">Neural Jump Diffusions (Neural Jump SDE) and Neural Partial Differential Equations (Neural PDEs)</a></li></ul></li><li><span class="tocitem">Bayesian Estimation Tutorials</span><ul><li><a class="tocitem" href="../../examples/turing_bayesian/">Bayesian Estimation of Differential Equations with Probabilistic Programming</a></li><li><a class="tocitem" href="../../examples/BayesianNODE_NUTS/">Bayesian Neural ODEs: NUTS</a></li><li><a class="tocitem" href="../../examples/BayesianNODE_SGLD/">Bayesian Neural ODEs: SGLD</a></li></ul></li><li><span class="tocitem">Optimal and Model Predictive Control Tutorials</span><ul><li><a class="tocitem" href="../../examples/optimal_control/">Solving Optimal Control Problems with Universal Differential Equations</a></li><li><a class="tocitem" href="../../examples/feedback_control/">Universal Differential Equations for Neural Feedback Control</a></li><li><a class="tocitem" href="../../examples/SDE_control/">Controlling Stochastic Differential Equations</a></li></ul></li><li><span class="tocitem">Universal Differential Equations and Physical Layer Tutorials</span><ul><li><a class="tocitem" href="../../examples/universal_diffeq/">Universal Ordinary, Stochastic, and Partial Differential Equation Examples</a></li><li><a class="tocitem" href="../../examples/tensor_layer/">Physics Informed Machine Learning with TensorLayer</a></li><li><a class="tocitem" href="../../examples/hamiltonian_nn/">Hamiltonian Neural Network</a></li></ul></li><li><span class="tocitem">Layer APIs</span><ul><li><a class="tocitem" href="../BasisLayers/">Classical Basis Layers</a></li><li><a class="tocitem" href="../TensorLayer/">Tensor Product Layer</a></li><li class="is-active"><a class="tocitem" href>Continuous Normalizing Flows Layer</a></li><li><a class="tocitem" href="../SplineLayer/">Spline Layer</a></li><li><a class="tocitem" href="../NeuralDELayers/">Neural Differential Equation Layers</a></li><li><a class="tocitem" href="../HamiltonianNN/">Hamiltonian Neural Network Layer</a></li></ul></li><li><span class="tocitem">Manual and APIs</span><ul><li><a class="tocitem" href="../../ControllingAdjoints/">Controlling Choices of Adjoints</a></li><li><a class="tocitem" href="../../Flux/">Use with Flux Chain and train!</a></li><li><a class="tocitem" href="../../FastChain/">FastChain</a></li><li><a class="tocitem" href="../../Collocation/">Smoothed Collocation</a></li><li><a class="tocitem" href="../../GPUs/">GPUs</a></li><li><a class="tocitem" href="../../sciml_train/">sciml_train and GalacticOptim.jl</a></li></ul></li><li><a class="tocitem" href="../../Benchmark/">Benchmarks</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Layer APIs</a></li><li class="is-active"><a href>Continuous Normalizing Flows Layer</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Continuous Normalizing Flows Layer</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/DiffEqFlux.jl/blob/master/docs/src/layers/CNFLayer.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="CNF-Layer-Functions"><a class="docs-heading-anchor" href="#CNF-Layer-Functions">CNF Layer Functions</a><a id="CNF-Layer-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#CNF-Layer-Functions" title="Permalink"></a></h1><p>The following layers are helper functions for easily building neural differential equation architectures specialized for the task of density estimation through Continuous Normalizing Flows (CNF).</p><article class="docstring"><header><a class="docstring-binding" id="DiffEqFlux.DeterministicCNF" href="#DiffEqFlux.DeterministicCNF"><code>DiffEqFlux.DeterministicCNF</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Constructs a continuous-time recurrent neural network, also known as a neural ordinary differential equation (neural ODE), with fast gradient calculation via adjoints [1] and specialized for density estimation based on continuous normalizing flows (CNF) [2] with a direct computation of the trace of the dynamics&#39; jacobian. At a high level this corresponds to the following steps:</p><ol><li>Parameterize the variable of interest x(t) as a function f(z, θ, t) of a base variable z(t) with known density p_z;</li><li>Use the transformation of variables formula to predict the density p<em>x as a function of the density p</em>z and the trace of the Jacobian of f;</li><li>Choose the parameter θ to minimize a loss function of p_x (usually the negative likelihood of the data);</li></ol><p>!!!note     This layer has been deprecated in favour of <code>FFJORD</code>. Use FFJORD with <code>monte_carlo=false</code> instead.</p><p>After these steps one may use the NN model and the learned θ to predict the density p_x for new values of x.</p><pre><code class="language-julia hljs">DeterministicCNF(model, tspan, basedist=nothing, monte_carlo=false, args...; kwargs...)</code></pre><p>Arguments:</p><ul><li><code>model</code>: A Chain neural network that defines the dynamics of the model.</li><li><code>basedist</code>: Distribution of the base variable. Set to the unit normal by default.</li><li><code>tspan</code>: The timespan to be solved on.</li><li><code>kwargs</code>: Additional arguments splatted to the ODE solver. See the <a href="https://diffeq.sciml.ai/dev/basics/common_solver_opts/">Common Solver Arguments</a> documentation for more details.</li></ul><p>References:</p><p>[1] Pontryagin, Lev Semenovich. Mathematical theory of optimal processes. CRC press, 1987.</p><p>[2] Chen, Ricky TQ, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. &quot;Neural ordinary differential equations.&quot; In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 6572-6583. 2018.</p><p>[3] Grathwohl, Will, Ricky TQ Chen, Jesse Bettencourt, Ilya Sutskever, and David Duvenaud. &quot;Ffjord: Free-form continuous dynamics for scalable reversible generative models.&quot; arXiv preprint arXiv:1810.01367 (2018).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DiffEqFlux.jl/blob/4a023438361963e6cc69441d210b4cb5871cb50d/src/ffjord.jl#L4-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiffEqFlux.FFJORD" href="#DiffEqFlux.FFJORD"><code>DiffEqFlux.FFJORD</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Constructs a continuous-time recurrent neural network, also known as a neural ordinary differential equation (neural ODE), with fast gradient calculation via adjoints [1] and specialized for density estimation based on continuous normalizing flows (CNF) [2] with a stochastic approach [2] for the computation of the trace of the dynamics&#39; jacobian. At a high level this corresponds to the following steps:</p><ol><li>Parameterize the variable of interest x(t) as a function f(z, θ, t) of a base variable z(t) with known density p_z;</li><li>Use the transformation of variables formula to predict the density p<em>x as a function of the density p</em>z and the trace of the Jacobian of f;</li><li>Choose the parameter θ to minimize a loss function of p_x (usually the negative likelihood of the data);</li></ol><p>After these steps one may use the NN model and the learned θ to predict the density p_x for new values of x.</p><pre><code class="language-julia hljs">FFJORD(model, basedist=nothing, monte_carlo=false, tspan, args...; kwargs...)</code></pre><p>Arguments:</p><ul><li><code>model</code>: A Chain neural network that defines the dynamics of the model.</li><li><code>basedist</code>: Distribution of the base variable. Set to the unit normal by default.</li><li><code>tspan</code>: The timespan to be solved on.</li><li><code>kwargs</code>: Additional arguments splatted to the ODE solver. See the <a href="https://diffeq.sciml.ai/dev/basics/common_solver_opts/">Common Solver Arguments</a> documentation for more details.</li></ul><p>References:</p><p>[1] Pontryagin, Lev Semenovich. Mathematical theory of optimal processes. CRC press, 1987.</p><p>[2] Chen, Ricky TQ, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. &quot;Neural ordinary differential equations.&quot; In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 6572-6583. 2018.</p><p>[3] Grathwohl, Will, Ricky TQ Chen, Jesse Bettencourt, Ilya Sutskever, and David Duvenaud. &quot;Ffjord: Free-form continuous dynamics for scalable reversible generative models.&quot; arXiv preprint arXiv:1810.01367 (2018).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DiffEqFlux.jl/blob/4a023438361963e6cc69441d210b4cb5871cb50d/src/ffjord.jl#L89-L121">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DiffEqFlux.FFJORDDistribution" href="#DiffEqFlux.FFJORDDistribution"><code>DiffEqFlux.FFJORDDistribution</code></a> — <span class="docstring-category">Type</span></header><section><div><p>FFJORD can be used as a distribution to generate new samples by <code>rand</code> or estimate densities by <code>pdf</code> or <code>logpdf</code> (from <code>Distributions.jl</code>).</p><p>Arguments:</p><ul><li><code>model</code>: A FFJORD instance</li><li><code>regularize</code>: Whether we use regularization (default: <code>false</code>)</li><li><code>monte_carlo</code>: Whether we use monte carlo (default: <code>true</code>)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DiffEqFlux.jl/blob/4a023438361963e6cc69441d210b4cb5871cb50d/src/ffjord.jl#L254-L262">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../TensorLayer/">« Tensor Product Layer</a><a class="docs-footer-nextpage" href="../SplineLayer/">Spline Layer »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.16 on <span class="colophon-date" title="Tuesday 3 May 2022 11:25">Tuesday 3 May 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
