<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimization of Stochastic Differential Equations · DiffEqFlux.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://diffeqflux.sciml.ai/stable/examples/optimization_sde/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="DiffEqFlux.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DiffEqFlux.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">DiffEqFlux.jl: Generalized Physics-Informed and Scientific Machine Learning (SciML)</a></li><li><span class="tocitem">Ordinary Differential Equation (ODE) Tutorials</span><ul><li><a class="tocitem" href="../optimization_ode/">Optimization of Ordinary Differential Equations</a></li><li><a class="tocitem" href="../stiff_ode_fit/">Parameter Estimation on Highly Stiff Systems</a></li><li><a class="tocitem" href="../neural_ode_sciml/">Neural Ordinary Differential Equations with sciml_train</a></li><li><a class="tocitem" href="../mnist_neural_ode/">GPU-based MNIST Neural ODE Classifier</a></li><li><a class="tocitem" href="../mnist_conv_neural_ode/">Convolutional Neural ODE MNIST Classifier on GPU</a></li><li><a class="tocitem" href="../augmented_neural_ode/">Augmented Neural Ordinary Differential Equations</a></li><li><a class="tocitem" href="../collocation/">Smoothed Collocation for Fast Two-Stage Training</a></li><li><a class="tocitem" href="../neural_gde/">Neural Graph Differential Equations</a></li><li><a class="tocitem" href="../exogenous_input/">Handling Exogenous Input Signals</a></li><li><a class="tocitem" href="../normalizing_flows/">Continuous Normalizing Flows with GalacticOptim.jl</a></li></ul></li><li><span class="tocitem">Direct Usage with Optimizer Backends</span><ul><li><a class="tocitem" href="../neural_ode_galacticoptim/">Neural Ordinary Differential Equations with GalacticOptim.jl</a></li><li><a class="tocitem" href="../neural_ode_flux/">Neural Ordinary Differential Equations with Flux.train!</a></li></ul></li><li><span class="tocitem">Training Techniques</span><ul><li><a class="tocitem" href="../multiple_shooting/">Multiple Shooting</a></li><li><a class="tocitem" href="../local_minima/">Strategies to Avoid Local Minima</a></li><li><a class="tocitem" href="../divergence/">Handling Divergent and Unstable Trajectories</a></li><li><a class="tocitem" href="../multiple_nn/">Simultaneous Fitting of Multiple Neural Networks</a></li><li><a class="tocitem" href="../data_parallel/">Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching</a></li><li><a class="tocitem" href="../second_order_neural/">Neural Second Order Ordinary Differential Equation</a></li><li><a class="tocitem" href="../second_order_adjoints/">Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis</a></li><li><a class="tocitem" href="../minibatch/">Training a Neural Ordinary Differential Equation with Mini-Batching</a></li></ul></li><li><span class="tocitem">Stochastic Differential Equation (SDE) Tutorials</span><ul><li class="is-active"><a class="tocitem" href>Optimization of Stochastic Differential Equations</a><ul class="internal"><li><a class="tocitem" href="#Example-1:-Fitting-Data-with-SDEs-via-Method-of-Moments-and-Parallelism"><span>Example 1: Fitting Data with SDEs via Method of Moments and Parallelism</span></a></li><li><a class="tocitem" href="#Example-2:-Fitting-SDEs-via-Bayesian-Quasi-Likelihood-Approaches"><span>Example 2: Fitting SDEs via Bayesian Quasi-Likelihood Approaches</span></a></li><li><a class="tocitem" href="#Example-3:-Controlling-SDEs-to-an-objective"><span>Example 3: Controlling SDEs to an objective</span></a></li></ul></li><li><a class="tocitem" href="../neural_sde/">Neural Stochastic Differential Equations</a></li></ul></li><li><span class="tocitem">Delay Differential Equation (DDE) Tutorials</span><ul><li><a class="tocitem" href="../delay_diffeq/">Delay Differential Equations</a></li></ul></li><li><span class="tocitem">Differential-Algebraic Equation (DAE) Tutorials</span><ul><li><a class="tocitem" href="../physical_constraints/">Enforcing Physical Constraints via Universal Differential-Algebraic Equations</a></li></ul></li><li><span class="tocitem">Partial Differential Equation (PDE) Tutorials</span><ul><li><a class="tocitem" href="../pde_constrained/">Partial Differential Equation (PDE) Constrained Optimization</a></li></ul></li><li><span class="tocitem">Hybrid and Jump Equation Tutorials</span><ul><li><a class="tocitem" href="../hybrid_diffeq/">Training Neural Networks in Hybrid Differential Equations</a></li><li><a class="tocitem" href="../bouncing_ball/">Bouncing Ball Hybrid ODE Optimization</a></li><li><a class="tocitem" href="../jump/">Neural Jump Diffusions (Neural Jump SDE) and Neural Partial Differential Equations (Neural PDEs)</a></li></ul></li><li><span class="tocitem">Bayesian Estimation Tutorials</span><ul><li><a class="tocitem" href="../turing_bayesian/">Bayesian Estimation of Differential Equations with Probabilistic Programming</a></li><li><a class="tocitem" href="../BayesianNODE_NUTS/">Bayesian Neural ODEs: NUTS</a></li><li><a class="tocitem" href="../BayesianNODE_SGLD/">Bayesian Neural ODEs: SGLD</a></li></ul></li><li><span class="tocitem">Optimal and Model Predictive Control Tutorials</span><ul><li><a class="tocitem" href="../optimal_control/">Solving Optimal Control Problems with Universal Differential Equations</a></li><li><a class="tocitem" href="../feedback_control/">Universal Differential Equations for Neural Feedback Control</a></li><li><a class="tocitem" href="../SDE_control/">Controlling Stochastic Differential Equations</a></li></ul></li><li><span class="tocitem">Universal Differential Equations and Physical Layer Tutorials</span><ul><li><a class="tocitem" href="../universal_diffeq/">Universal Ordinary, Stochastic, and Partial Differential Equation Examples</a></li><li><a class="tocitem" href="../tensor_layer/">Physics Informed Machine Learning with TensorLayer</a></li><li><a class="tocitem" href="../hamiltonian_nn/">Hamiltonian Neural Network</a></li></ul></li><li><span class="tocitem">Layer APIs</span><ul><li><a class="tocitem" href="../../layers/BasisLayers/">Classical Basis Layers</a></li><li><a class="tocitem" href="../../layers/TensorLayer/">Tensor Product Layer</a></li><li><a class="tocitem" href="../../layers/CNFLayer/">Continuous Normalizing Flows Layer</a></li><li><a class="tocitem" href="../../layers/SplineLayer/">Spline Layer</a></li><li><a class="tocitem" href="../../layers/NeuralDELayers/">Neural Differential Equation Layers</a></li><li><a class="tocitem" href="../../layers/HamiltonianNN/">Hamiltonian Neural Network Layer</a></li></ul></li><li><span class="tocitem">Manual and APIs</span><ul><li><a class="tocitem" href="../../ControllingAdjoints/">Controlling Choices of Adjoints</a></li><li><a class="tocitem" href="../../Flux/">Use with Flux Chain and train!</a></li><li><a class="tocitem" href="../../FastChain/">FastChain</a></li><li><a class="tocitem" href="../../Collocation/">Smoothed Collocation</a></li><li><a class="tocitem" href="../../GPUs/">GPUs</a></li><li><a class="tocitem" href="../../sciml_train/">sciml_train and GalacticOptim.jl</a></li></ul></li><li><a class="tocitem" href="../../Benchmark/">Benchmarks</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Stochastic Differential Equation (SDE) Tutorials</a></li><li class="is-active"><a href>Optimization of Stochastic Differential Equations</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimization of Stochastic Differential Equations</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/DiffEqFlux.jl/blob/master/docs/src/examples/optimization_sde.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimization-of-Stochastic-Differential-Equations"><a class="docs-heading-anchor" href="#Optimization-of-Stochastic-Differential-Equations">Optimization of Stochastic Differential Equations</a><a id="Optimization-of-Stochastic-Differential-Equations-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-of-Stochastic-Differential-Equations" title="Permalink"></a></h1><p>Here we demonstrate <code>sensealg = ForwardDiffSensitivity()</code> (provided by DiffEqSensitivity.jl) for forward-mode automatic differentiation of a small stochastic differential equation. For large parameter equations, like neural stochastic differential equations, you should use reverse-mode automatic differentiation. However, forward-mode can be more efficient for low numbers of parameters (&lt;100). (Note: the default is reverse-mode AD which is more suitable for things like neural SDEs!)</p><h2 id="Example-1:-Fitting-Data-with-SDEs-via-Method-of-Moments-and-Parallelism"><a class="docs-heading-anchor" href="#Example-1:-Fitting-Data-with-SDEs-via-Method-of-Moments-and-Parallelism">Example 1: Fitting Data with SDEs via Method of Moments and Parallelism</a><a id="Example-1:-Fitting-Data-with-SDEs-via-Method-of-Moments-and-Parallelism-1"></a><a class="docs-heading-anchor-permalink" href="#Example-1:-Fitting-Data-with-SDEs-via-Method-of-Moments-and-Parallelism" title="Permalink"></a></h2><p>Let&#39;s do the most common scenario: fitting data. Let&#39;s say our ecological system is a stochastic process. Each time we solve this equation we get a different solution, so we need a sensible data source.</p><pre><code class="language-julia hljs">using DiffEqFlux, DifferentialEquations, Plots
function lotka_volterra!(du,u,p,t)
  x,y = u
  α,β,γ,δ = p
  du[1] = dx = α*x - β*x*y
  du[2] = dy = δ*x*y - γ*y
end
u0 = [1.0,1.0]
tspan = (0.0,10.0)

function multiplicative_noise!(du,u,p,t)
  x,y = u
  du[1] = p[5]*x
  du[2] = p[6]*y
end
p = [1.5,1.0,3.0,1.0,0.3,0.3]

prob = SDEProblem(lotka_volterra!,multiplicative_noise!,u0,tspan,p)
sol = solve(prob)
plot(sol)</code></pre><p><img src="https://user-images.githubusercontent.com/1814174/88511873-97bc0a00-cfb3-11ea-8cf5-5930b6575d9d.png" alt/></p><p>Let&#39;s assume that we are observing the seasonal behavior of this system and have 10,000 years of data, corresponding to 10,000 observations of this timeseries. We can utilize this to get the seasonal means and variances. To simulate that scenario, we will generate 10,000 trajectories from the SDE to build our dataset:</p><pre><code class="language-julia hljs">using Statistics
ensembleprob = EnsembleProblem(prob)
@time sol = solve(ensembleprob,SOSRI(),saveat=0.1,trajectories=10_000)
truemean = mean(sol,dims=3)[:,:]
truevar  = var(sol,dims=3)[:,:]</code></pre><p>From here, we wish to utilize the method of moments to fit the SDE&#39;s parameters. Thus our loss function will be to solve the SDE a bunch of times and compute moment equations and use these as our loss against the original series. We then plot the evolution of the means and variances to verify the fit. For example:</p><pre><code class="language-julia hljs">function loss(p)
  tmp_prob = remake(prob,p=p)
  ensembleprob = EnsembleProblem(tmp_prob)
  tmp_sol = solve(ensembleprob,SOSRI(),saveat=0.1,trajectories=1000)
  arrsol = Array(tmp_sol)
  sum(abs2,truemean - mean(arrsol,dims=3)) + 0.1sum(abs2,truevar - var(arrsol,dims=3)),arrsol
end

function cb2(p,l,arrsol)
  @show p,l
  means = mean(arrsol,dims=3)[:,:]
  vars = var(arrsol,dims=3)[:,:]
  p1 = plot(sol[1].t,means&#39;,lw=5)
  scatter!(p1,sol[1].t,truemean&#39;)
  p2 = plot(sol[1].t,vars&#39;,lw=5)
  scatter!(p2,sol[1].t,truevar&#39;)
  p = plot(p1,p2,layout = (2,1))
  display(p)
  false
end</code></pre><p>We can then use <code>sciml_train</code> to fit the SDE:</p><pre><code class="language-julia hljs">pinit = [1.2,0.8,2.5,0.8,0.1,0.1]
@time res = DiffEqFlux.sciml_train(loss,pinit,ADAM(0.05),cb=cb2,maxiters = 100)</code></pre><p>The final print out was:</p><pre><code class="language-julia hljs">(p, l) = ([1.5242134195974462, 1.019859938499017, 2.9120928257869227, 0.9840408090733335, 0.29427123791721765, 0.3334393815923646], 1.7046719990657184)</code></pre><p>Notice that <strong>both the parameters of the deterministic drift equations and the stochastic portion (the diffusion equation) are fit through this process!</strong> Also notice that the final fit of the moment equations is close:</p><p><img src="https://user-images.githubusercontent.com/1814174/88511872-97bc0a00-cfb3-11ea-9d44-a3ed96a77df9.png" alt/></p><p>The time for the full fitting process was:</p><pre><code class="nohighlight hljs">250.654845 seconds (4.69 G allocations: 104.868 GiB, 11.87% gc time)</code></pre><p>approximately 4 minutes.</p><h2 id="Example-2:-Fitting-SDEs-via-Bayesian-Quasi-Likelihood-Approaches"><a class="docs-heading-anchor" href="#Example-2:-Fitting-SDEs-via-Bayesian-Quasi-Likelihood-Approaches">Example 2: Fitting SDEs via Bayesian Quasi-Likelihood Approaches</a><a id="Example-2:-Fitting-SDEs-via-Bayesian-Quasi-Likelihood-Approaches-1"></a><a class="docs-heading-anchor-permalink" href="#Example-2:-Fitting-SDEs-via-Bayesian-Quasi-Likelihood-Approaches" title="Permalink"></a></h2><p>An inference method which can be much more efficient in many cases is the quasi-likelihood approach. This approach matches the random likelihood of the SDE output with the random sampling of a Bayesian inference problem to more efficiently directly estimate the posterior distribution. For more information, please see <a href="https://github.com/TuringLang/TuringTutorials/blob/master/10_diffeq.ipynb">the Turing.jl Bayesian Differential Equations tutorial</a></p><h2 id="Example-3:-Controlling-SDEs-to-an-objective"><a class="docs-heading-anchor" href="#Example-3:-Controlling-SDEs-to-an-objective">Example 3: Controlling SDEs to an objective</a><a id="Example-3:-Controlling-SDEs-to-an-objective-1"></a><a class="docs-heading-anchor-permalink" href="#Example-3:-Controlling-SDEs-to-an-objective" title="Permalink"></a></h2><p>In this example, we will find the parameters of the SDE that force the solution to be close to the constant 1.</p><pre><code class="language-julia hljs">using DifferentialEquations, DiffEqFlux, Plots

function lotka_volterra!(du, u, p, t)
  x, y = u
  α, β, δ, γ = p
  du[1] = dx = α*x - β*x*y
  du[2] = dy = -δ*y + γ*x*y
end

function lotka_volterra_noise!(du, u, p, t)
  du[1] = 0.1u[1]
  du[2] = 0.1u[2]
end

u0 = [1.0,1.0]
tspan = (0.0, 10.0)
p = [2.2, 1.0, 2.0, 0.4]
prob_sde = SDEProblem(lotka_volterra!, lotka_volterra_noise!, u0, tspan)


function predict_sde(p)
  return Array(solve(prob_sde, SOSRI(), p=p,
               sensealg = ForwardDiffSensitivity(), saveat = 0.1))
end

loss_sde(p) = sum(abs2, x-1 for x in predict_sde(p))</code></pre><p>For this training process, because the loss function is stochastic, we will use the <code>ADAM</code> optimizer from Flux.jl. The <code>sciml_train</code> function is the same as before. However, to speed up the training process, we will use a global counter so that way we only plot the current results every 10 iterations. This looks like:</p><pre><code class="language-julia hljs">callback = function (p, l)
  display(l)
  remade_solution = solve(remake(prob_sde, p = p), SOSRI(), saveat = 0.1)
  plt = plot(remade_solution, ylim = (0, 6))
  display(plt)
  return false
end</code></pre><p>Let&#39;s optimize</p><pre><code class="language-julia hljs">result_sde = DiffEqFlux.sciml_train(loss_sde, p, ADAM(0.1),
                                    cb = callback, maxiters = 100)</code></pre><p><img src="https://user-images.githubusercontent.com/1814174/51399524-2c6abf80-1b14-11e9-96ae-0192f7debd03.gif" alt/></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../minibatch/">« Training a Neural Ordinary Differential Equation with Mini-Batching</a><a class="docs-footer-nextpage" href="../neural_sde/">Neural Stochastic Differential Equations »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.14 on <span class="colophon-date" title="Saturday 12 March 2022 10:18">Saturday 12 March 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
